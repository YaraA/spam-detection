{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "import os\n",
    "import pyphen\n",
    "import sklearn_crfsuite\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn_crfsuite import scorers\n",
    "from nltk import pos_tag, word_tokenize, sent_tokenize\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Part 1: Reading and Preprocessing Data\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Reads the emails from dataset.\n",
    "Classify the email as a spam or not (1/0) according to the file name and\n",
    "returns the email's contents and the email's class.\n",
    "\"\"\"\n",
    "def read_mails():\n",
    "    mails_targets = []\n",
    "    mails_data = []\n",
    "    for root, dirs, _ in os.walk('bare/'):\n",
    "        for sub_dir in dirs:\n",
    "            for root, dirs, files in os.walk('bare/' + sub_dir):\n",
    "                for file in files:\n",
    "                    f = open(os.path.join('bare/' + sub_dir, file), 'r')\n",
    "                    mails_data.append(f.read())\n",
    "                    if \"spm\" in file:\n",
    "                        mails_targets.append(1)\n",
    "                    else:\n",
    "                        mails_targets.append(0)\n",
    "                    f.close()\n",
    "    return mails_data, mails_targets\n",
    "\n",
    "\"\"\"\n",
    "Part 2: Scikit-Learn Classifiers\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Takes the classifier, vectorizer, training data, test data, test targets and type of classifier.\n",
    "Feeds a classifier using the training data and labels then\n",
    "predicts on the testing data whether an email is ham or spam then\n",
    "compars the predictions made with the testing labels and\n",
    "returns the precision, recall and fscore of the classifier on the testing data.\n",
    "\"\"\"\n",
    "def metrics_classifier(model, vectorizer, train_mails, test_mails, test_targets, model_name):\n",
    "    model.fit(train_mails, train_targets)\n",
    "    transformed_test = vectorizer.transform(test_mails)\n",
    "    predictions = model.predict(transformed_test)\n",
    "    (precision, recall, fscore, _) = metrics.precision_recall_fscore_support(test_targets, predictions, average='macro')\n",
    "    print(model_name)\n",
    "    print(\"Precision:\",precision, \"Recall:\", recall, \"Fscore:\", fscore)\n",
    "    return precision, recall, fscore\n",
    "\n",
    "\"\"\"\n",
    "Fits and transforms the training data using the vectorizer.\n",
    "Intializes and finds the metrics of the three classifiers:\n",
    "a) Multinomial Naive Bayes\n",
    "b) K Neighbors Classifier\n",
    "c) Random Forest Classifier\n",
    "\"\"\"\n",
    "def classification(v, train_mails, train_targets, test_mails, test_targets):\n",
    "    train_mails = v.fit_transform(train_mails)\n",
    "\n",
    "    nb_clf = MultinomialNB()\n",
    "    precision, recall, fscore = metrics_classifier(nb_clf, v, train_mails, test_mails, test_targets, \"Multinomial Naive Bayes\")\n",
    "\n",
    "    kn_clf = KNeighborsClassifier()\n",
    "    precision, recall, fscore = metrics_classifier(kn_clf, v, train_mails, test_mails, test_targets, \"K Neighbors Classifier\")\n",
    "\n",
    "    rf_clf = RandomForestClassifier(random_state=0)\n",
    "    precision, recall, fscore = metrics_classifier(rf_clf, v, train_mails, test_mails, test_targets, \"Random Forest Classifier\")\n",
    "\n",
    "\"\"\"\n",
    "Part 3: Classifying using Readability Features\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Reads the spam phrases from the spam list.\n",
    "\"\"\"\n",
    "def read_spams_phrases():\n",
    "    spam_words = []\n",
    "    with open('spam_words.txt', 'r') as f:\n",
    "        spam_words = f.read()\n",
    "    return spam_words.split('\\n')[:-1]\n",
    "\n",
    "\"\"\"\n",
    "Counts the number of occurances of each spam phrase in an email.\n",
    "\"\"\"\n",
    "def count_spam_phrases(email):\n",
    "    count = 0\n",
    "    for spam in spam_phrases:\n",
    "        count += email.count(spam)\n",
    "    return count\n",
    "\n",
    "\"\"\"\n",
    "Counts the number of verbs in an email.\n",
    "\"\"\"\n",
    "def count_verbs(email):\n",
    "    for sentence in sent_tokenize(email):\n",
    "        word_tags = pos_tag(word_tokenize(sentence))\n",
    "        count = 0\n",
    "        for word in word_tags:\n",
    "            if word[1] == 'VBZ':\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "\"\"\"\n",
    "Checks if a word contains both digits and alphabets.\n",
    "\"\"\"\n",
    "def contains_num_alpha(word):\n",
    "    find_num = find_alpha = False\n",
    "    for c in word:\n",
    "        find_num = find_num or c.isdigit()\n",
    "        find_alpha = find_alpha or c.isalpha()\n",
    "    return find_num and find_alpha\n",
    "\n",
    "\"\"\"\n",
    "Counts the number of words containing both digits and alphabets in an email.\n",
    "\"\"\"\n",
    "def count_num_alpha(email):\n",
    "    count = 0\n",
    "    for word in word_tokenize(email):\n",
    "        if contains_num_alpha(word):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\"\"\"\n",
    "Counts the number of words containing 3 syllables in an email.\n",
    "\"\"\"\n",
    "def count_3_syllables(email):\n",
    "    count = 0\n",
    "    dic = pyphen.Pyphen(lang='en_GB')\n",
    "    for word in word_tokenize(email):\n",
    "        syllables_in_word = len(dic.inserted(word).split('-'))\n",
    "        if syllables_in_word >= 3:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\"\"\"\n",
    "Finds the average number of syllables in all words in an email.\n",
    "\"\"\"\n",
    "def avg_syllables(email):\n",
    "    syllables_in_words = 0\n",
    "    dic = pyphen.Pyphen(lang='en_GB')\n",
    "    words = word_tokenize(email)\n",
    "    for word in words:\n",
    "        syllables_in_words += len(dic.inserted(word).split('-'))\n",
    "    avg = syllables_in_words // len(words)\n",
    "    return avg\n",
    "\n",
    "\"\"\"\n",
    "Extracts features from each email.\n",
    "F1: The number of sentences in an email.\n",
    "F2: The number of verbs in an email.\n",
    "F3: The number of words containing both numeric and alphabetical characters.\n",
    "F4: The number of words in an email that are found in the spam list.\n",
    "F5: The number of words in an email that have more than 3 syllables.\n",
    "F6: The average number of syllables of words in an email.\n",
    "\"\"\"\n",
    "def email2features(email):\n",
    "    features = {\n",
    "        'sents_count': len(sent_tokenize(email)),\n",
    "        'verbs_count': count_verbs(email),\n",
    "        'num_alpha_count': count_num_alpha(email),\n",
    "        'spam_sentences_count': count_spam_phrases(email),\n",
    "        '3_syllables_count': count_3_syllables(email),\n",
    "        'avg_syllables': avg_syllables(email)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\"\"\"\n",
    "Builds a feature matrix (list of dicts), where every row corresponds to an email, and every column corresponds to a feature value of this email.\n",
    "\"\"\"\n",
    "def build_features_matrix(emails):\n",
    "    matrix = []\n",
    "    for email in emails:\n",
    "        features = email2features(email)\n",
    "        matrix.append(features)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "mails_data, mails_targets = read_mails()\n",
    "split = int(0.8 * len(mails_data))\n",
    "train_mails = mails_data[:split]\n",
    "train_targets = mails_targets[:split]\n",
    "test_mails = mails_data[split:]\n",
    "test_targets = mails_targets[split:]\n",
    "\n",
    "spam_phrases = read_spams_phrases()\n",
    "\n",
    "cv = CountVectorizer()\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_features = build_features_matrix(train_mails)\n",
    "test_features = build_features_matrix(test_mails)\n",
    "\n",
    "print(\"Classifying using email's whole text content\")\n",
    "classification(cv, train_mails, train_targets, test_mails, test_targets)\n",
    "print(\"Classifying using Readability Features\")\n",
    "classification(dv, train_features, train_targets, test_features, test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
